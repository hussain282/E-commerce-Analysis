{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96cf89f7-a85e-4fd1-88cf-a9fa0d29c67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Original shape: (50000, 10)\n",
      "\n",
      "1. Handling missing values...\n",
      "\n",
      "2. Removing duplicates...\n",
      "Shape after deduplication: (50000, 10)\n",
      "\n",
      "3. Converting data types...\n",
      "\n",
      "4. Engineering new features...\n",
      "\n",
      "5. Handling outliers...\n",
      "Shape after outlier removal: (50000, 16)\n",
      "\n",
      "6. Validating data...\n",
      "\n",
      "7. Saving cleaned data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13756\\2752910925.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_cleaned['traffic_source'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Cleaning complete! Final shape: (50000, 16)\n",
      "✅ Saved to: C:\\Users\\HP\\Desktop\\ecommerce_dashboard_project\\cleaned_data\\cleaned.csv\n",
      "\n",
      "=== CLEANED DATA SUMMARY ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   order_id          50000 non-null  object        \n",
      " 1   order_date        50000 non-null  datetime64[ns]\n",
      " 2   customer_id       50000 non-null  object        \n",
      " 3   product_category  50000 non-null  object        \n",
      " 4   product_name      50000 non-null  object        \n",
      " 5   quantity          50000 non-null  int64         \n",
      " 6   unit_price        50000 non-null  int64         \n",
      " 7   customer_country  50000 non-null  object        \n",
      " 8   traffic_source    50000 non-null  object        \n",
      " 9   total_price       50000 non-null  int64         \n",
      " 10  order_year        50000 non-null  int32         \n",
      " 11  order_month       50000 non-null  int32         \n",
      " 12  order_quarter     50000 non-null  int32         \n",
      " 13  order_month_name  50000 non-null  object        \n",
      " 14  order_weekday     50000 non-null  object        \n",
      " 15  is_high_value     50000 non-null  bool          \n",
      "dtypes: bool(1), datetime64[ns](1), int32(3), int64(3), object(8)\n",
      "memory usage: 5.2+ MB\n",
      "None\n",
      "\n",
      "Missing values after cleaning:\n",
      "order_id            0\n",
      "order_date          0\n",
      "customer_id         0\n",
      "product_category    0\n",
      "product_name        0\n",
      "quantity            0\n",
      "unit_price          0\n",
      "customer_country    0\n",
      "traffic_source      0\n",
      "total_price         0\n",
      "order_year          0\n",
      "order_month         0\n",
      "order_quarter       0\n",
      "order_month_name    0\n",
      "order_weekday       0\n",
      "is_high_value       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# save as: data/processed/clean_data.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_ecommerce_data(input_path, output_path):\n",
    "    print(\"Loading raw data...\")\n",
    "    df = pd.read_csv(input_path)\n",
    "    \n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    print(f\"Original shape: {df_cleaned.shape}\")\n",
    "    \n",
    "    # Step 1: Handle missing values\n",
    "    print(\"\\n1. Handling missing values...\")\n",
    "   \n",
    "    df_cleaned['traffic_source'].fillna('Unknown', inplace=True)\n",
    "    \n",
    "    # Step 2: Remove duplicates\n",
    "    print(\"\\n2. Removing duplicates...\")\n",
    "    df_cleaned.drop_duplicates(inplace=True)\n",
    "    print(f\"Shape after deduplication: {df_cleaned.shape}\")\n",
    "    \n",
    "    # Step 3: Data type conversion\n",
    "    print(\"\\n3. Converting data types...\")\n",
    "    df_cleaned['order_date'] = pd.to_datetime(df_cleaned['order_date'])\n",
    "    df_cleaned['order_id'] = df_cleaned['order_id'].astype(str)\n",
    "    df_cleaned['customer_id'] = df_cleaned['customer_id'].astype(str)\n",
    "    \n",
    "    # Step 4: Feature Engineering\n",
    "    print(\"\\n4. Engineering new features...\")\n",
    "    \n",
    "    # Revenue metrics\n",
    "    df_cleaned['total_price'] = df_cleaned['unit_price'] * df_cleaned['quantity']\n",
    "    \n",
    "    # Time-based features\n",
    "    df_cleaned['order_year'] = df_cleaned['order_date'].dt.year\n",
    "    df_cleaned['order_month'] = df_cleaned['order_date'].dt.month\n",
    "    df_cleaned['order_quarter'] = df_cleaned['order_date'].dt.quarter\n",
    "    df_cleaned['order_month_name'] = df_cleaned['order_date'].dt.month_name()\n",
    "    df_cleaned['order_weekday'] = df_cleaned['order_date'].dt.day_name()\n",
    "    \n",
    "    # Customer metrics\n",
    "    df_cleaned['is_high_value'] = df_cleaned['total_price'] > df_cleaned['total_price'].quantile(0.8)\n",
    "    \n",
    "    # Step 5: Remove outliers (optional but recommended)\n",
    "    print(\"\\n5. Handling outliers...\")\n",
    "    # Remove orders with unrealistic quantities (>50)\n",
    "    outlier_mask = df_cleaned['quantity'] <= 50\n",
    "    df_cleaned = df_cleaned[outlier_mask]\n",
    "    print(f\"Shape after outlier removal: {df_cleaned.shape}\")\n",
    "    \n",
    "    # Step 6: Validate data integrity\n",
    "    print(\"\\n6. Validating data...\")\n",
    "    assert df_cleaned['order_id'].is_unique, \"Order IDs should be unique\"\n",
    "    assert df_cleaned['total_price'].min() >= 0, \"Revenue cannot be negative\"\n",
    "    assert df_cleaned['order_date'].min() >= pd.Timestamp('2022-01-01'), \"Date out of range\"\n",
    "    \n",
    "    # Step 7: Save cleaned data\n",
    "    print(\"\\n7. Saving cleaned data...\")\n",
    "    df_cleaned.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n✅ Cleaning complete! Final shape: {df_cleaned.shape}\")\n",
    "    print(f\"✅ Saved to: {output_path}\")\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Execute the cleaning\n",
    "if __name__ == \"__main__\":\n",
    "    INPUT_PATH = r\"C:\\Users\\HP\\Desktop\\ecommerce_dashboard_project\\raw_data\\raw_data.csv\"\n",
    "    OUTPUT_PATH = r\"C:\\Users\\HP\\Desktop\\ecommerce_dashboard_project\\cleaned_data\\cleaned.csv\"\n",
    "    \n",
    "    cleaned_df = clean_ecommerce_data(INPUT_PATH, OUTPUT_PATH)\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n=== CLEANED DATA SUMMARY ===\")\n",
    "    print(cleaned_df.info())\n",
    "    print(\"\\nMissing values after cleaning:\")\n",
    "    print(cleaned_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d604d031-cade-4de5-ab27-a4189b1c6f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating daily aggregates...\n",
      "Creating monthly aggregates...\n",
      "Creating product performance...\n",
      "✅ All master files created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned data\n",
    "df = pd.read_csv(r\"C:\\Users\\HP\\Desktop\\ecommerce_dashboard_project\\cleaned_data\\cleaned.csv\")\n",
    "df['order_date'] = pd.to_datetime(df['order_date'])\n",
    "\n",
    "# 1. Daily aggregated data\n",
    "print(\"Creating daily aggregates...\")\n",
    "daily_agg = df.groupby('order_date').agg({\n",
    "    'order_id': 'count',\n",
    "    'total_price': 'sum',\n",
    "    'customer_id': 'nunique'\n",
    "}).rename(columns={\n",
    "    'order_id': 'orders',\n",
    "    'total_price': 'revenue',\n",
    "    'customer_id': 'unique_customers'\n",
    "}).reset_index()\n",
    "\n",
    "daily_agg['aov'] = daily_agg['revenue'] / daily_agg['orders']\n",
    "daily_agg.to_csv(r\"C:\\Users\\HP\\Desktop\\ecommerce_dashboard_project\\cleaned_data/daily_metrics.csv\", index=False)\n",
    "\n",
    "# 2. Monthly aggregated data\n",
    "print(\"Creating monthly aggregates...\")\n",
    "monthly_agg = df.groupby(['order_year', 'order_month']).agg({\n",
    "    'order_id': 'count',\n",
    "    'total_price': 'sum',\n",
    "    'customer_id': 'nunique'\n",
    "}).rename(columns={\n",
    "    'order_id': 'orders',\n",
    "    'total_price': 'revenue',\n",
    "    'customer_id': 'unique_customers'\n",
    "}).reset_index()\n",
    "\n",
    "monthly_agg['aov'] = monthly_agg['revenue'] / monthly_agg['orders']\n",
    "monthly_agg.to_csv(r\"C:\\Users\\HP\\Desktop\\ecommerce_dashboard_project\\cleaned_data/monthly_metrics.csv\", index=False)\n",
    "\n",
    "# 3. Product performance\n",
    "print(\"Creating product performance...\")\n",
    "product_perf = df.groupby(['product_category', 'product_name']).agg({\n",
    "    'order_id': 'count',\n",
    "    'total_price': 'sum',\n",
    "    'quantity': 'sum'\n",
    "}).rename(columns={\n",
    "    'order_id': 'orders',\n",
    "    'total_price': 'revenue',\n",
    "    'quantity': 'units_sold'\n",
    "}).reset_index()\n",
    "\n",
    "product_perf.to_csv(r\"C:\\Users\\HP\\Desktop\\ecommerce_dashboard_project\\cleaned_data/product_performance.csv\", index=False)\n",
    "\n",
    "print(\"✅ All master files created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee34dc47-c1b3-49b9-a292-d9fe0e7ad950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
